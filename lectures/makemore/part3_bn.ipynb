{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# makemore: part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097\n"
     ]
    }
   ],
   "source": [
    "# MLP revisited\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5) #* 0.2\n",
    "#b1 = torch.randn(n_hidden,                        generator=g) * 0.01\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.zeros((1, n_hidden))\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2736\n",
      "  10000/ 200000: 2.3246\n",
      "  20000/ 200000: 2.0229\n",
      "  30000/ 200000: 2.0292\n",
      "  40000/ 200000: 2.0587\n",
      "  50000/ 200000: 2.8989\n",
      "  60000/ 200000: 2.1025\n",
      "  70000/ 200000: 2.8280\n",
      "  80000/ 200000: 2.5755\n",
      "  90000/ 200000: 2.2545\n",
      " 100000/ 200000: 2.0482\n",
      " 110000/ 200000: 1.8211\n",
      " 120000/ 200000: 1.8397\n",
      " 130000/ 200000: 2.4059\n",
      " 140000/ 200000: 2.4866\n",
      " 150000/ 200000: 2.4214\n",
      " 160000/ 200000: 2.1187\n",
      " 170000/ 200000: 2.1708\n",
      " 180000/ 200000: 2.1542\n",
      " 190000/ 200000: 2.0988\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb] # embed the characters into vectors\n",
    "  embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "  # Linear layer\n",
    "  hpreact = embcat @ W1 #+ b1 # hidden layer pre-activation\n",
    "  # BatchNorm layer\n",
    "  # -------------------------------------------------------------\n",
    "  bnmeani = hpreact.mean(0, keepdim=True)\n",
    "  bnstdi = hpreact.std(0, keepdim=True)\n",
    "  hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias\n",
    "  with torch.no_grad():\n",
    "    bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
    "    bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
    "  # -------------------------------------------------------------\n",
    "  # Non-linearity\n",
    "  h = torch.tanh(hpreact) # hidden layer\n",
    "  logits = h @ W2 + b2 # output layer\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15a880640>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(h.abs() > .99, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(h.view(-1).tolist(), 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(hpreact.view(-1).tolist(), 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.6601e-02,  7.1294e-02,  4.0797e-02,  3.1149e-02,  1.9894e-02,\n",
       "         -3.9361e-03, -2.6331e-02,  5.2819e-02,  1.1655e-02, -3.3673e-02,\n",
       "         -1.0199e-01, -1.0497e-01,  4.3396e-02,  3.9557e-02,  4.0937e-02,\n",
       "         -4.9429e-02,  5.8889e-02, -1.5894e-02,  3.3501e-02, -6.7133e-02,\n",
       "          1.7686e-01,  1.1971e-01,  3.9865e-02, -7.5818e-02,  1.2355e-02,\n",
       "          1.4911e-01,  1.0603e-02],\n",
       "        [ 1.0623e-01, -2.7774e-02,  9.9652e-02, -1.6168e-01, -1.5425e-02,\n",
       "          2.8836e-02,  2.1820e-02,  7.5374e-02,  8.8941e-02,  1.8936e-01,\n",
       "          1.6575e-01,  8.8573e-02, -8.7338e-02, -1.2033e-02, -1.7971e-01,\n",
       "         -1.7784e-02,  7.4010e-02,  6.2871e-02, -4.1428e-02,  4.4932e-03,\n",
       "          1.8114e-02, -9.8291e-02,  4.7093e-02, -5.1549e-02, -1.5212e-02,\n",
       "         -5.0449e-02, -1.0519e-02],\n",
       "        [-1.7255e-02, -5.9798e-02,  2.6640e-02,  4.5777e-02,  1.4452e-01,\n",
       "          5.8254e-02, -1.1822e-01, -4.5599e-02, -2.6903e-01, -2.4332e-02,\n",
       "         -1.8600e-01, -1.7182e-01,  3.8857e-02,  1.9046e-01,  7.4544e-02,\n",
       "          1.2827e-01,  5.9213e-03, -7.7423e-02, -3.6308e-02, -2.7183e-02,\n",
       "          6.3546e-02,  9.9104e-03, -7.7928e-02,  3.2505e-01, -8.6469e-03,\n",
       "          5.0553e-02,  1.1360e-02],\n",
       "        [ 3.3231e-02, -8.6165e-02,  6.6355e-02,  3.9398e-03,  1.5434e-01,\n",
       "          1.4473e-01,  4.6512e-02,  1.1355e-01, -1.2563e-02, -3.5092e-03,\n",
       "          4.0064e-02, -6.6499e-02,  3.0262e-02,  1.0334e-01, -3.4010e-02,\n",
       "         -2.2291e-02,  2.3303e-02, -1.0225e-01,  1.0794e-01,  8.1842e-02,\n",
       "          1.1762e-02, -7.4613e-03, -2.6043e-02, -8.3843e-02,  5.7399e-02,\n",
       "          3.4869e-02,  4.8693e-02],\n",
       "        [-1.2245e-01, -7.0718e-02, -1.4009e-01,  4.2274e-02, -6.9030e-02,\n",
       "         -1.0164e-01,  1.0783e-01, -7.8882e-02, -5.7973e-02, -7.1261e-03,\n",
       "          4.4886e-02,  2.6384e-02, -1.5183e-01,  5.5063e-02,  1.3982e-01,\n",
       "          4.2797e-02, -4.4289e-02, -3.1366e-02, -8.5364e-02,  3.0836e-02,\n",
       "          4.6925e-02, -1.2053e-02,  3.7055e-02,  2.2955e-01, -3.9786e-02,\n",
       "         -1.7383e-02, -1.9320e-01],\n",
       "        [ 3.5168e-02, -6.1993e-02, -3.8017e-02, -1.1950e-02,  3.7740e-05,\n",
       "          2.0477e-01, -5.9021e-02,  1.6152e-01,  1.6820e-04, -1.8251e-01,\n",
       "          6.6730e-02, -1.1073e-01, -1.2968e-01,  1.2179e-04, -2.6198e-02,\n",
       "         -5.4279e-02, -7.6938e-02,  1.3826e-02, -2.5927e-02, -1.1967e-01,\n",
       "          2.9829e-02,  3.6604e-02, -1.8951e-02,  6.5935e-02, -4.4049e-02,\n",
       "          8.3308e-02, -5.8486e-02],\n",
       "        [ 1.3628e-01, -6.8211e-02,  9.2037e-02,  7.8839e-02, -3.5611e-02,\n",
       "          1.2998e-01, -5.7213e-02,  1.7217e-01,  2.5392e-01,  2.0275e-01,\n",
       "          1.2924e-01,  1.4420e-01, -7.3830e-02,  3.6714e-02, -2.0115e-01,\n",
       "         -1.7224e-01, -1.0787e-01, -6.5027e-02, -1.5801e-01,  5.6784e-02,\n",
       "          5.4359e-02,  1.1165e-01, -2.6735e-02,  1.0714e-01, -1.4187e-01,\n",
       "         -2.8795e-02,  5.1772e-02],\n",
       "        [-5.7602e-02,  6.9180e-02,  4.7293e-02,  1.0228e-03,  1.0105e-01,\n",
       "         -5.2138e-03, -1.6470e-01, -1.7409e-02, -1.1107e-01, -8.7207e-02,\n",
       "         -7.2844e-02, -1.2376e-01, -6.1111e-02,  4.3700e-02, -2.2453e-02,\n",
       "         -3.1504e-02,  1.0344e-01,  2.0311e-01,  1.7778e-01, -3.1184e-02,\n",
       "         -1.8717e-01,  4.7298e-02,  7.5099e-02, -9.6352e-02,  5.8291e-02,\n",
       "          9.7895e-02,  1.0654e-01],\n",
       "        [-5.8842e-02,  4.6553e-02,  1.5081e-01, -5.4057e-02,  9.2165e-02,\n",
       "          6.2131e-02, -1.2407e-01,  1.8490e-02, -1.0749e-01, -7.8744e-02,\n",
       "         -7.6183e-02, -2.5530e-02,  6.3211e-02,  1.0242e-01,  3.2076e-02,\n",
       "         -1.5631e-03, -1.4087e-02, -9.4999e-02,  5.6899e-02, -1.4163e-02,\n",
       "         -1.2316e-01, -5.7354e-02, -5.6557e-03, -4.6811e-02,  1.4868e-01,\n",
       "          1.7192e-01,  9.3408e-02],\n",
       "        [ 4.7819e-02, -1.1971e-01, -6.0460e-02,  5.8907e-02, -1.1598e-01,\n",
       "         -1.7280e-01,  3.2053e-02,  4.1629e-04,  2.1818e-01, -4.0235e-03,\n",
       "          7.7974e-02,  1.6876e-01,  1.8084e-02, -4.6891e-02, -1.3813e-01,\n",
       "         -7.4695e-03, -1.4890e-01,  1.0989e-02, -2.1189e-01, -1.2102e-01,\n",
       "          2.3214e-01,  8.3309e-04, -3.8115e-02,  8.7571e-02, -5.5494e-02,\n",
       "         -1.2755e-01, -1.0694e-01],\n",
       "        [ 1.4050e-01, -8.1552e-02,  5.9774e-02,  1.1449e-01,  5.7833e-02,\n",
       "         -2.8427e-02,  3.7046e-02, -9.2379e-02,  1.6394e-01,  9.0831e-02,\n",
       "          5.9116e-02,  3.1331e-02,  1.2010e-01, -1.6555e-01, -1.4356e-01,\n",
       "         -6.3761e-02,  6.6314e-02,  6.8640e-02,  3.9717e-02,  8.3644e-03,\n",
       "         -1.4028e-01,  7.5386e-02, -2.7270e-02, -2.5301e-01, -7.0853e-02,\n",
       "         -4.6349e-02, -4.5698e-02],\n",
       "        [ 3.1162e-02,  4.5274e-02,  8.1653e-02,  3.0283e-02, -1.2127e-02,\n",
       "         -2.0672e-02, -3.0496e-02, -3.7443e-02,  1.7843e-01,  1.1254e-01,\n",
       "          4.8382e-02, -3.0734e-02, -1.8668e-02, -1.5299e-01, -7.0280e-02,\n",
       "         -6.1588e-02,  1.4387e-01,  2.5613e-02, -6.2692e-02,  5.2428e-02,\n",
       "          6.6053e-02,  6.5234e-02,  1.3895e-02,  1.1176e-01, -1.5221e-01,\n",
       "         -8.9017e-02, -2.5262e-02],\n",
       "        [-6.2276e-02,  4.7269e-04, -4.1980e-02, -8.5072e-02, -1.0430e-01,\n",
       "         -3.2941e-02,  2.4553e-02,  3.2218e-02, -1.4278e-01, -1.6652e-01,\n",
       "         -3.9495e-02,  1.2942e-01, -6.9724e-02,  4.8802e-02, -1.4360e-01,\n",
       "          1.8672e-02, -2.4659e-02, -4.7381e-03, -4.3585e-02, -9.0247e-02,\n",
       "          3.1771e-02, -1.6154e-01,  6.0403e-02, -9.1660e-03,  1.1517e-01,\n",
       "         -9.6461e-02, -2.2592e-02],\n",
       "        [ 4.6938e-02,  1.2795e-01,  7.9294e-02, -3.7072e-02,  1.5501e-02,\n",
       "         -7.5265e-02, -5.8706e-03,  1.9924e-02,  4.6156e-02,  4.8919e-02,\n",
       "         -7.1507e-02,  3.6048e-02,  1.1271e-01, -8.7376e-02, -9.0719e-03,\n",
       "          2.6706e-02,  7.4246e-02, -1.2758e-01,  1.6673e-01,  1.2147e-01,\n",
       "         -1.3614e-01, -9.8608e-02,  2.8309e-02, -2.2384e-01,  9.7381e-04,\n",
       "         -7.7091e-02,  1.2454e-01],\n",
       "        [-2.2022e-02, -1.5900e-02, -4.4599e-02, -6.6773e-02,  7.6083e-02,\n",
       "          1.5666e-02,  6.0340e-02, -7.2078e-02,  9.5236e-02,  2.9374e-02,\n",
       "         -7.8673e-02,  8.2140e-02,  2.0498e-01, -1.6692e-01,  2.3869e-02,\n",
       "          1.2150e-01,  3.3075e-02,  8.8358e-02,  9.7904e-03,  9.1556e-02,\n",
       "         -2.5882e-01,  6.9046e-04, -2.4007e-02, -3.6491e-01,  2.5884e-02,\n",
       "         -7.9881e-02, -1.4046e-02],\n",
       "        [ 5.0739e-03,  9.0063e-02,  1.2347e-01, -6.3713e-02, -4.0896e-02,\n",
       "         -4.4290e-02, -7.4040e-02, -5.2596e-02,  7.6731e-02, -6.9738e-02,\n",
       "          8.2887e-02, -1.1175e-01,  2.1085e-02, -1.1287e-01,  1.8439e-02,\n",
       "          6.2473e-02,  4.0661e-02,  5.9677e-02,  6.6881e-02, -4.7207e-02,\n",
       "          1.0399e-01, -1.2053e-02,  5.7000e-02,  1.4302e-01, -1.0612e-01,\n",
       "         -5.7477e-03, -4.4468e-02],\n",
       "        [-1.0990e-01,  9.5346e-02,  9.5851e-02,  6.6973e-03,  1.8073e-01,\n",
       "          6.3839e-03, -1.4038e-02, -1.2282e-01, -1.6654e-01, -7.5336e-02,\n",
       "         -8.3885e-02, -2.3892e-01,  1.2877e-01,  7.7542e-02,  2.3476e-01,\n",
       "          9.4018e-02,  9.6467e-02, -2.6679e-02,  3.8750e-03,  6.5514e-02,\n",
       "          6.0409e-02,  1.0585e-01, -6.1686e-02, -1.8665e-02,  7.8711e-03,\n",
       "          2.0049e-01, -6.2781e-02],\n",
       "        [-4.6601e-02,  7.1294e-02,  4.0797e-02,  3.1149e-02,  1.9894e-02,\n",
       "         -3.9361e-03, -2.6331e-02,  5.2819e-02,  1.1655e-02, -3.3673e-02,\n",
       "         -1.0199e-01, -1.0497e-01,  4.3396e-02,  3.9557e-02,  4.0937e-02,\n",
       "         -4.9429e-02,  5.8889e-02, -1.5894e-02,  3.3501e-02, -6.7133e-02,\n",
       "          1.7686e-01,  1.1971e-01,  3.9865e-02, -7.5818e-02,  1.2355e-02,\n",
       "          1.4911e-01,  1.0603e-02],\n",
       "        [ 3.3962e-02,  5.6799e-02, -7.2826e-02, -1.3132e-01,  1.4710e-02,\n",
       "          5.0395e-03, -1.0456e-01, -2.5138e-02,  9.3496e-02,  1.6121e-02,\n",
       "         -5.7697e-02,  9.1385e-02,  8.4918e-03,  1.3899e-01, -1.1754e-01,\n",
       "          5.0517e-02, -1.8403e-01,  7.3338e-03, -5.0124e-02, -1.9221e-02,\n",
       "         -2.6252e-01,  8.8018e-04, -1.0395e-02,  1.9302e-02,  3.0104e-02,\n",
       "         -2.3396e-02,  1.1932e-01],\n",
       "        [-9.7820e-02, -1.1781e-01, -1.3754e-01, -3.4419e-02, -2.4555e-01,\n",
       "         -8.2558e-02,  2.8046e-01,  9.0558e-02,  1.0549e-01,  1.6887e-02,\n",
       "          7.6768e-02,  1.5865e-01, -1.0308e-01, -3.4587e-02, -4.8417e-02,\n",
       "         -8.4521e-02, -4.5288e-02, -9.2335e-03,  8.3565e-02,  4.2709e-02,\n",
       "          1.6609e-01, -1.6773e-02,  4.0068e-02, -5.8184e-02,  7.1466e-02,\n",
       "         -2.3450e-02, -5.8360e-02],\n",
       "        [-1.1971e-01,  5.0836e-02,  4.1906e-02, -4.5764e-03,  1.8867e-01,\n",
       "          9.2274e-02, -6.9018e-02, -1.6336e-01, -1.4095e-01, -1.3500e-02,\n",
       "         -1.4174e-01, -7.4070e-02,  1.6223e-02, -1.2251e-01,  1.3078e-01,\n",
       "          7.1656e-02,  3.3251e-02, -5.8363e-02,  1.3973e-02,  2.7261e-02,\n",
       "          4.8384e-02, -5.0687e-02, -1.4454e-02,  6.7448e-02,  1.0010e-01,\n",
       "         -1.0116e-01, -3.3652e-02],\n",
       "        [ 3.1285e-02,  6.5102e-02,  2.1621e-02, -6.8312e-02,  3.2958e-02,\n",
       "         -5.6561e-02,  4.7573e-02, -3.8774e-02,  7.9097e-02,  5.7613e-02,\n",
       "         -2.0855e-02,  5.0044e-02,  1.4677e-01, -1.1647e-01,  1.9308e-03,\n",
       "          6.1943e-02,  1.9592e-02, -9.8459e-02,  1.3828e-01,  1.1971e-01,\n",
       "         -1.8301e-01, -1.0398e-01, -1.2995e-02, -2.3996e-01, -6.8169e-03,\n",
       "         -8.3155e-02,  1.0914e-01],\n",
       "        [-9.9807e-02, -1.2525e-02, -1.4628e-01, -3.4985e-02, -1.0251e-01,\n",
       "         -1.2841e-01,  1.6822e-01, -1.3677e-01, -8.1742e-02,  1.4257e-02,\n",
       "          4.1432e-02,  6.1901e-02, -3.7486e-02,  2.9360e-02,  6.8984e-02,\n",
       "          2.8322e-02, -1.8004e-02, -2.1751e-02,  1.5931e-01,  3.2936e-02,\n",
       "         -4.7450e-02, -1.9232e-02,  1.1364e-02, -1.8421e-01,  1.3612e-01,\n",
       "         -3.9247e-02, -1.3544e-01],\n",
       "        [-5.2547e-02,  1.0625e-01, -2.0265e-01,  5.4853e-02, -6.3450e-02,\n",
       "         -7.2170e-02, -3.9528e-02, -5.5574e-02, -1.5745e-01, -7.6536e-02,\n",
       "         -1.1698e-02, -2.4017e-02, -1.3985e-01,  1.0341e-02,  1.7070e-01,\n",
       "          6.5428e-02, -2.8981e-02,  1.3446e-01, -1.6036e-01, -4.7721e-02,\n",
       "         -1.2396e-01,  1.9243e-02, -8.5735e-02,  1.7149e-01, -7.9594e-02,\n",
       "          1.5831e-02, -1.2272e-01],\n",
       "        [ 1.7297e-01, -6.6313e-02,  3.4582e-02,  7.4576e-02, -5.9822e-02,\n",
       "          9.4659e-02, -1.4886e-01,  2.0728e-01,  2.2035e-01,  2.9240e-01,\n",
       "          1.4400e-01,  1.4788e-01, -7.9534e-02,  8.2400e-02, -2.4936e-01,\n",
       "         -1.3190e-01, -1.0689e-01,  4.2063e-02, -1.3029e-01,  5.0984e-02,\n",
       "          4.4898e-02,  1.1932e-01, -9.6740e-02,  8.3651e-02, -2.3232e-01,\n",
       "          7.3297e-02,  2.0783e-01],\n",
       "        [ 4.5795e-02, -2.0047e-02,  3.6874e-02, -1.9524e-02, -6.6852e-02,\n",
       "         -1.2725e-01,  7.9205e-03,  9.1817e-02,  2.8676e-02,  4.9900e-02,\n",
       "         -2.3509e-02,  4.0089e-02, -4.7198e-02, -3.6315e-02, -5.0304e-02,\n",
       "         -9.0770e-02,  5.1020e-02,  9.2652e-03,  1.6336e-01, -1.4557e-02,\n",
       "         -4.2423e-03, -5.0349e-02, -1.4942e-02,  1.3656e-01, -1.4634e-01,\n",
       "         -4.8384e-02,  2.9877e-02],\n",
       "        [-3.1077e-02, -9.5783e-02,  6.2620e-02, -1.0434e-02,  1.2542e-01,\n",
       "          9.2421e-02,  3.9303e-02, -1.5321e-02, -1.0660e-01,  2.3684e-02,\n",
       "         -1.3885e-01, -4.2561e-02,  8.3753e-02, -3.5099e-03,  8.1046e-03,\n",
       "          8.1086e-02, -2.2279e-02, -1.3579e-01,  2.5096e-02,  5.7879e-02,\n",
       "         -1.0721e-01, -7.3132e-02, -6.8985e-02,  6.7063e-02,  6.4478e-02,\n",
       "         -5.4680e-02,  1.0530e-01],\n",
       "        [-1.2730e-01, -1.9083e-01, -2.5076e-02,  1.2481e-02,  3.6580e-02,\n",
       "          4.9460e-02,  1.5632e-01,  4.5134e-02, -1.2463e-01, -1.3818e-01,\n",
       "          2.0515e-01, -1.8696e-02, -5.6453e-02,  1.0093e-01,  1.3850e-02,\n",
       "         -1.7977e-02, -2.0811e-02, -1.6035e-02,  2.7494e-02, -9.4909e-03,\n",
       "         -4.5999e-02, -1.1615e-02,  3.0227e-02, -3.1146e-02,  1.2209e-01,\n",
       "          1.1199e-01, -1.2831e-01],\n",
       "        [ 5.9088e-02,  7.6439e-02, -3.2010e-02,  4.2983e-02, -3.8219e-02,\n",
       "          2.1302e-02, -5.5204e-02, -9.0312e-02,  1.0388e-03, -3.7243e-02,\n",
       "         -3.9455e-02, -7.1220e-02,  2.4953e-02, -3.8775e-02,  1.8619e-02,\n",
       "          1.2139e-01,  1.1679e-02, -2.4779e-02, -1.5089e-01, -7.0789e-02,\n",
       "          1.2157e-01,  7.9713e-03,  4.3156e-02,  8.2258e-02, -6.3035e-02,\n",
       "         -6.1707e-02, -1.0117e-02],\n",
       "        [-3.5438e-02,  4.8137e-03,  9.6524e-02,  3.6354e-02,  5.8150e-02,\n",
       "          1.0833e-01,  2.2794e-02,  9.8015e-03,  3.0440e-02, -4.7919e-02,\n",
       "         -3.5169e-03, -1.2029e-01,  3.9577e-02, -4.5858e-02,  4.6939e-02,\n",
       "          9.4975e-02,  1.8241e-02, -1.0027e-01, -1.6941e-01, -1.0827e-01,\n",
       "          1.4381e-01,  1.1181e-01, -2.5582e-02,  4.5392e-02, -4.9309e-02,\n",
       "          1.3141e-01, -4.1127e-02],\n",
       "        [-4.6601e-02,  7.1294e-02,  4.0797e-02,  3.1149e-02,  1.9894e-02,\n",
       "         -3.9361e-03, -2.6331e-02,  5.2819e-02,  1.1655e-02, -3.3673e-02,\n",
       "         -1.0199e-01, -1.0497e-01,  4.3396e-02,  3.9557e-02,  4.0937e-02,\n",
       "         -4.9429e-02,  5.8889e-02, -1.5894e-02,  3.3501e-02, -6.7133e-02,\n",
       "          1.7686e-01,  1.1971e-01,  3.9865e-02, -7.5818e-02,  1.2355e-02,\n",
       "          1.4911e-01,  1.0603e-02],\n",
       "        [ 5.5568e-03,  1.0437e-01, -4.6940e-02, -2.6548e-02, -3.8451e-02,\n",
       "         -1.1224e-01, -9.5221e-02, -1.9580e-01, -1.3513e-02, -1.6739e-02,\n",
       "         -2.4970e-02,  6.1105e-02,  4.4065e-02, -1.5662e-01,  4.4793e-03,\n",
       "          5.6741e-02, -4.6677e-02, -4.6319e-03,  6.8984e-03, -2.2094e-02,\n",
       "          3.3557e-02, -1.5982e-01,  7.4299e-02,  4.7091e-02,  4.7077e-02,\n",
       "         -2.5303e-01, -6.0624e-02]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-torch.tensor(1/27.0).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 # + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnstd = hpreact.std(0, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 # + b1\n",
    "  #hpreact = bngain * (hpreact - hpreact.mean(0, keepdim=True)) / hpreact.std(0, keepdim=True) + bnbias\n",
    "  hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss log\n",
    "\n",
    "### original:\n",
    "train 2.1245384216308594\n",
    "val   2.168196439743042\n",
    "\n",
    "### fix softmax confidently wrong:\n",
    "train 2.07\n",
    "val   2.13\n",
    "\n",
    "### fix tanh layer too saturated at init:\n",
    "train 2.0355966091156006\n",
    "val   2.1026785373687744\n",
    "\n",
    "### use semi-principled \"kaiming init\" instead of hacky init:\n",
    "train 2.0376641750335693\n",
    "val   2.106989622116089\n",
    "\n",
    "### add batch norm layer\n",
    "train 2.0668270587921143\n",
    "val 2.104844808578491\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY + PYTORCHIFYING -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train a deeper network\n",
    "# The classes we create here are the same API as nn.Module in PyTorch\n",
    "\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      xmean = x.mean(0, keepdim=True) # batch mean\n",
    "      xvar = x.var(0, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 100 # the number of neurons in the hidden layer of the MLP\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "layers = [\n",
    "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, vocab_size, bias=False), BatchNorm1d(vocab_size),\n",
    "]\n",
    "# layers = [\n",
    "#   Linear(n_embd * block_size, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, vocab_size),\n",
    "# ]\n",
    "\n",
    "with torch.no_grad():\n",
    "  # last layer: make less confident\n",
    "  layers[-1].gamma *= 0.1\n",
    "  #layers[-1].weight *= 0.1\n",
    "  # all other layers: apply gain\n",
    "  for layer in layers[:-1]:\n",
    "    if isinstance(layer, Linear):\n",
    "      layer.weight *= 1.0 #5/3\n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb] # embed the characters into vectors\n",
    "  x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "  for layer in layers:\n",
    "    x = layer(x)\n",
    "  loss = F.cross_entropy(x, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for layer in layers:\n",
    "    layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  with torch.no_grad():\n",
    "    ud.append([((lr*p.grad).std() / p.data.std()).log10().item() for p in parameters])\n",
    "\n",
    "  if i >= 1000:\n",
    "    break # AFTER_DEBUG: would take out obviously to run full optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
    "  if isinstance(layer, Tanh):\n",
    "    t = layer.out\n",
    "    print('layer %d (%10s): mean %+.2f, std %.2f, saturated: %.2f%%' % (i, layer.__class__.__name__, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('activation distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
    "  if isinstance(layer, Tanh):\n",
    "    t = layer.out.grad\n",
    "    print('layer %d (%10s): mean %+f, std %e' % (i, layer.__class__.__name__, t.mean(), t.std()))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('gradient distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i,p in enumerate(parameters):\n",
    "  t = p.grad\n",
    "  if p.ndim == 2:\n",
    "    print('weight %10s | mean %+f | std %e | grad:data ratio %e' % (tuple(p.shape), t.mean(), t.std(), t.std() / p.std()))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'{i} {tuple(p.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights gradient distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for i,p in enumerate(parameters):\n",
    "  if p.ndim == 2:\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append('param %d' % i)\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  x = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  for layer in layers:\n",
    "    x = layer(x)\n",
    "  loss = F.cross_entropy(x, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,n_embd)\n",
    "      x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "      for layer in layers:\n",
    "        x = layer(x)\n",
    "      logits = x\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE; BONUS content below, not covered in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchNorm forward pass as a widget\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "def normshow(x0):\n",
    "  \n",
    "  g = torch.Generator().manual_seed(2147483647+1)\n",
    "  x = torch.randn(5, generator=g) * 5\n",
    "  x[0] = x0 # override the 0th example with the slider\n",
    "  mu = x.mean()\n",
    "  sig = x.std()\n",
    "  y = (x - mu)/sig\n",
    "\n",
    "  plt.figure(figsize=(10, 5))\n",
    "  # plot 0\n",
    "  plt.plot([-6,6], [0,0], 'k')\n",
    "  # plot the mean and std\n",
    "  xx = np.linspace(-6, 6, 100)\n",
    "  plt.plot(xx, stats.norm.pdf(xx, mu, sig), 'b')\n",
    "  xx = np.linspace(-6, 6, 100)\n",
    "  plt.plot(xx, stats.norm.pdf(xx, 0, 1), 'r')\n",
    "  # plot little lines connecting input and output\n",
    "  for i in range(len(x)):\n",
    "    plt.plot([x[i],y[i]], [1, 0], 'k', alpha=0.2)\n",
    "  # plot the input and output values\n",
    "  plt.scatter(x.data, torch.ones_like(x).data, c='b', s=100)\n",
    "  plt.scatter(y.data, torch.zeros_like(y).data, c='r', s=100)\n",
    "  plt.xlim(-6, 6)\n",
    "  # title\n",
    "  plt.title('input mu %.2f std %.2f' % (mu, sig))\n",
    "\n",
    "interact(normshow, x0=(-30,30,0.5));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear: activation statistics of forward and backward pass\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "a = torch.randn((1000,1), requires_grad=True, generator=g)          # a.grad = b.T @ c.grad\n",
    "b = torch.randn((1000,1000), requires_grad=True, generator=g)       # b.grad = c.grad @ a.T\n",
    "c = b @ a\n",
    "loss = torch.randn(1000, generator=g) @ c\n",
    "a.retain_grad()\n",
    "b.retain_grad()\n",
    "c.retain_grad()\n",
    "loss.backward()\n",
    "print('a std:', a.std().item())\n",
    "print('b std:', b.std().item())\n",
    "print('c std:', c.std().item())\n",
    "print('-----')\n",
    "print('c grad std:', c.grad.std().item())\n",
    "print('a grad std:', a.grad.std().item())\n",
    "print('b grad std:', b.grad.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear + BatchNorm: activation statistics of forward and backward pass\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "n = 1000\n",
    "# linear layer ---\n",
    "inp = torch.randn(n, requires_grad=True, generator=g)\n",
    "w = torch.randn((n, n), requires_grad=True, generator=g) # / n**0.5\n",
    "x = w @ inp\n",
    "# bn layer ---\n",
    "xmean = x.mean()\n",
    "xvar = x.var()\n",
    "out = (x - xmean) / torch.sqrt(xvar + 1e-5)\n",
    "# ----\n",
    "loss = out @ torch.randn(n, generator=g)\n",
    "inp.retain_grad()\n",
    "x.retain_grad()\n",
    "w.retain_grad()\n",
    "out.retain_grad()\n",
    "loss.backward()\n",
    "\n",
    "print('inp std: ', inp.std().item())\n",
    "print('w std: ', w.std().item())\n",
    "print('x std: ', x.std().item())\n",
    "print('out std: ', out.std().item())\n",
    "print('------')\n",
    "print('out grad std: ', out.grad.std().item())\n",
    "print('x grad std: ', x.grad.std().item())\n",
    "print('w grad std: ', w.grad.std().item())\n",
    "print('inp grad std: ', inp.grad.std().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
